# -*- coding: utf-8 -*-
"""prediksi penyakit diabetes dengan pembelajaran mesin.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h9QzLaWZCKtHW7azHJd6bKxKYE5vg7y3

# Algoritma Klasifikasi machine Learning
prediksi Penyakit Diabetes

**input Database dan Requimen.txt**
"""

!git clone https://github.com/maritzaaamar/Machine-learning

# Commented out IPython magic to ensure Python compatibility.
# Importing libraries
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics
from sklearn.model_selection import cross_val_score

import warnings
warnings.filterwarnings('ignore')
# %matplotlib inline

#Read Dataset
df = pd.read_csv("/content/Machine-learning/diabetes.csv")

"""data awal"""

#Show Ascending Data
df.head(5)

"""data akhir"""

#Show Descinding Data
df.tail(5)

"""histogram yang ter identifikasi dan tidak"""

# Outcome countplot
sns.countplot(x = 'Outcome',data = df)

# Histogram of each feature
import itertools

col = df.columns[:8]
plt.subplots(figsize = (20, 15))
length = len(col)

for i, j in itertools.zip_longest(col, range(length)):
    plt.subplot((length/2), 3, j + 1)
    plt.subplots_adjust(wspace = 0.1,hspace = 0.5)
    df[i].hist(bins = 20)
    plt.title(i)
plt.show()



#Cek Data Null
df.isnull().values.any()

#plot Korelasi Data (Data Double)
def plot_corr(df, size=11):
    #Data Core Correlation
    corr = df.corr()
    fig, ax = plt.subplots(figsize=(size, size))
    ax.matshow(corr)
    plt.xticks(range(len(corr.columns)), corr.columns)
    plt.yticks(range(len(corr.columns)), corr.columns)

plot_corr(df)

# Heatmap
sns.heatmap(df.corr(), annot = True)
plt.show()

#Cek Korelasi Data
df.corr()

#Jumlah distribusi

#Panjang data
num_obs = len(df)
#Cek jumlah true
num_true = len(df.loc[df['Outcome'] == 1])
#Cek Jumlah False
num_false = len(df.loc[df['Outcome'] == 0])
print("Jumlah Diabetes : {0} ({1:2.2f}%)".format(num_true, (num_true/num_obs) * 100))
print("Jumlah tidak Diabetes : {0} ({1:2.2f}%)".format(num_false, (num_false/num_obs) * 100))

"""# **Proces Training**

membagi data 70% training dan 30% testing untuk pengujian
"""

#Split data
from sklearn.model_selection import train_test_split
feature_col_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']
predicted_class_names = ['Outcome']

X = df[feature_col_names].values
y = df[predicted_class_names].values
split_test_size = 0.30

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = split_test_size, random_state = 42)

print("{0:0.2f}% ada pada training set".format((len(X_train)/len(df.index)) * 100))
print("{0:0.2f}% ada pada test set".format((len(X_test)/len(df.index)) * 100))

#cek split data
print("Jumlah Original terkena Diabetes : {0} ({1:2.2f}%)".format(len(df.loc[df['Outcome'] == 1]), (len(df.loc[df['Outcome'] == 1])/len(df.index)) * 100.0))
print("Jumlah Original tidak terkena Diabetes : {0} ({1:2.2f}%)".format(len(df.loc[df['Outcome'] == 0]), (len(df.loc[df['Outcome'] == 0])/len(df.index)) * 100.0))
print("")
print("Training True : {0} ({1:2.2f}%)".format(len(y_train[y_train[:] == 1]), (len(y_train[y_train[:] == 1])/len(y_train) * 100.0)))
print("Training False : {0} ({1:2.2f}%)".format(len(y_train[y_train[:] == 0]), (len(y_train[y_train[:] == 0])/len(y_train) * 100.0)))
print("")
print("Testing True : {0} ({1:2.2f}%)".format(len(y_test[y_test[:] == 1]), (len(y_test[y_test[:] == 1])/len(y_test) * 100.0)))
print("TestingTraining False : {0} ({1:2.2f}%)".format(len(y_test[y_test[:] == 0]), (len(y_test[y_test[:] == 0])/len(y_test) * 100.0)))

"""**pra-pengolahan**
melihat data yang bernilai 0 atau bernilai 1
"""

df.head()

print("# rows in datframe {0}".format(len(df)))
print("# rows missing Glucose: {0}".format(len(df.loc[df['Glucose'] == 0])))
print("# rows missing BloodPressure: {0}".format(len(df.loc[df['BloodPressure'] == 0])))
print("# rows missing SkinThickness: {0}".format(len(df.loc[df['SkinThickness'] == 0])))
print("# rows missing Insulin: {0}".format(len(df.loc[df['Insulin'] == 0])))
print("# rows missing BMI: {0}".format(len(df.loc[df['BMI'] == 0])))
print("# rows missing DiabetesPedigreeFunction: {0}".format(len(df.loc[df['DiabetesPedigreeFunction'] == 0])))
print("# rows missing Age: {0}".format(len(df.loc[df['Age'] == 0])))

#Impute Data yang kosong dengan min 
from sklearn.impute import SimpleImputer
fill_0 = SimpleImputer(missing_values = 0, strategy = "mean")
X_train = fill_0.fit_transform(X_train)
X_test = fill_0.fit_transform(X_test)

df.head()

"""# **Naive Bayes** """

# import naive bayes
from sklearn.naive_bayes import GaussianNB

# buat model naive bayes
nb_model = GaussianNB()

# train model naive bayes
nb_model.fit(X_train, y_train.ravel())

#Training Naive Bayes
from sklearn.naive_bayes import GaussianNB
nb_model = GaussianNB()

nb_model.fit(X_train, y_train.ravel())

# Test Akurasi Data Train
nb_predict_train = nb_model.predict(X_train)
gnb_score_train = metrics.accuracy_score(y_train, nb_predict_train)*100
from sklearn import metrics
print("Accuracy:", gnb_score_train)

# Test Akurasi Data Uji
nb_predict_test = nb_model.predict(X_test)
gnb_score_test = metrics.accuracy_score(y_test, nb_predict_test) * 100

from sklearn import metrics
#print("nb_predict_test", nb_predict_test)
#print("y_test", y_test)
print("Accuracy:", gnb_score_test)

#Konfusion Matriks (Cek label)
print("Confusion Matrix")
cm = "{0}".format(metrics.confusion_matrix(y_test, nb_predict_test))
print(cm)
print("Classification Report")
print(metrics.classification_report(y_test, nb_predict_test))

"""**Naive Bayes** CrossValidation"""

gnb_cv = np.mean(cross_val_score(nb_model, X, y, cv=10) * 100)
print("10-Fold Cross-Validation score Regular Training Set:", gnb_cv)

"""# **Logistic Regression**"""

from sklearn.linear_model import LogisticRegression

lr_model = LogisticRegression(C=0.7, random_state = 42, solver = 'liblinear', max_iter = 10000)
lr_model.fit(X_train, y_train.ravel())
lr_predict_test = lr_model.predict(X_test)

print("Accuracy: {0:.4f}".format(metrics.accuracy_score(y_test, lr_predict_test)*100))
print("{0}".format(metrics.confusion_matrix(y_test, lr_predict_test)))
print("")
print("Classification Report")
print(metrics.classification_report(y_test, lr_predict_test))

# Commented out IPython magic to ensure Python compatibility.
#Setting Regularisize Parameter, supaya semua kelas weightnya balance (terkena dan tidak terkena diabetes)
C_start = 0.1
C_end = 5
C_inc = 0.1

C_values, recall_scores = [], []

C_val = C_start
best_recall_score = 0
while (C_val < C_end):
    C_values.append(C_val)
    lr_model_loop = LogisticRegression(C = C_val, class_weight = "balanced", random_state = 42, solver = 'liblinear', max_iter = 100)
    lr_model_loop.fit(X_train, y_train.ravel())
    lr_predict_loop_test = lr_model_loop.predict(X_test)
    recall_score = metrics.recall_score(y_test, lr_predict_loop_test)
    recall_scores.append(recall_score)
    if(recall_score > best_recall_score):
        best_recall_score = recall_score
        best_lr_predict_test = lr_predict_loop_test
        
    C_val = C_val + C_inc
    
best_score_C_val = C_values[recall_scores.index(best_recall_score)]
print("1st max value of {0:.3f} occured at C={1:.3f}".format(best_recall_score, best_score_C_val))

# %matplotlib inline
plt.plot(C_values, recall_scores, "-")
plt.xlabel("C value")
plt.ylabel("Recall Score")

#Kelas Weight yang sudah balance
from sklearn.linear_model import LogisticRegression
lr_model = LogisticRegression(class_weight = "balanced", C = best_score_C_val, random_state = 42, solver = 'liblinear')
lr_model.fit(X_train, y_train.ravel())
lr_predict_test = lr_model.predict(X_test)

#Training Matriks
print("Accuracy: {0:.4f}".format(metrics.accuracy_score(y_test, lr_predict_test)*100))
print("{0}".format(metrics.confusion_matrix(y_test, lr_predict_test)))
print("")
print("Classification Report")
print(metrics.classification_report(y_test, lr_predict_test))
print(metrics.recall_score(y_test, lr_predict_test)*100)

"""**Cross Validation** Logistic Regression"""

lr_cv = np.mean(cross_val_score(lr_model, X, y, cv=10) * 100)
print("10-Fold Cross-Validation score Regular Training Set:", lr_cv)

from sklearn.linear_model import LogisticRegressionCV
lr_cv_model = LogisticRegressionCV(n_jobs =- 1, random_state = 42, Cs = 3, cv = 10, refit = False, class_weight = "balanced", max_iter = 500)
lr_cv_model.fit(X_train, y_train.ravel())

#Prediksi Test Data
lr_cv_predict_test = lr_cv_model.predict(X_test)

print("Acccuracy : {0:.4f}".format(metrics.accuracy_score(y_test, lr_cv_predict_test)*100))
print(metrics.confusion_matrix(y_test, lr_cv_predict_test))
print("")
print("Classification Report")
print(metrics.classification_report(y_test, lr_cv_predict_test))



"""# **Random Forest Classifier**"""

#Peningkatan peforma akurasi dengan RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(random_state = 42, n_estimators = 10)
rf_model.fit(X_train, y_train.ravel())

#Prediksi Data train
rf_predict_train = rf_model.predict(X_train)

print("Accuracy: {0:.4f}".format(metrics.accuracy_score(y_train, rf_predict_train)*100))

#Prediksi Data Uji
rf_predict_test = rf_model.predict(X_test)

print("Accuracy: {0:.4f}".format(metrics.accuracy_score(y_test, rf_predict_test)*100))

rf_score = metrics.accuracy_score(y_test, rf_predict_test) * 100
#Konfusion Matriks (Cek label)
print("Confusion Matrix")
print("{0}".format(metrics.confusion_matrix(y_test, rf_predict_test)))
print("")
### Print classification report
print("Classification report for {}:\n{}".format(rf_model , metrics.classification_report(y_test, rf_predict_test)))
print("Accuracy score:", rf_score)

"""**Random Forest Classifier**
Cross-Validation 
"""

rf_cv = np.mean(cross_val_score(rf_model, X, y, cv=10) * 100)
print("10-Fold Cross-Validation score for RF fit in Regular Training Set:", rf_cv)

#Konfusion Matriks (Cek label)
print("Confusion Matrix")
print("{0}".format(metrics.confusion_matrix(y_test, rf_predict_test)))
print("")
print("Classification Report")
print(metrics.classification_report(y_test, rf_predict_test))

"""# perbandingan **accuracy score** dengan **cross-validation**"""

DataFrame = len(df)
# lr_cv = metrics.accuracy_score(y_test, lr_predict_test)*100

df_results = pd.DataFrame.from_dict({
    'Accuracy Score':{'Logistic Regression':legostic, 'Gaussian Naive Bayes':gnb_score_test, 'Random Forest':rf_score},
    'Cross-Validation Score':{'Logistic Regression':lr_cv, 'Gaussian Naive Bayes':gnb_cv, 'Random Forest':rf_cv}
    })
df_results

